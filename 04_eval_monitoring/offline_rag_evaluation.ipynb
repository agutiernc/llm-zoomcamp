{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc0da69-e1d4-45a4-a572-d352a0a7c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ec0818-44ac-44bd-a648-1aac4f9d5114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'ea739c65'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182f3e63-e36a-404b-9f27-e51a8e78bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a115af8-bda8-4b60-8f7b-59aada276b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pd.read_csv('ground-truth-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c1206aa-1c96-4934-8ac1-be8150e07c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52353363-dbbb-443f-8193-64cb9ce7ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Are sessions recorded if I miss one?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '5170565b'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8793a1-361d-433c-b6d8-e4b759c99b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fetch by id\n",
    "doc_idx = {d['id']: d for d in documents}\n",
    "\n",
    "doc_idx['5170565b']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e79e208-897e-4e97-8b15-f469b7173121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use elsastic search and index the documents\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28418eb-b9be-41d1-91fb-3b800b86c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33cdf7a9-de46-4f10-8616-57635f93daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997916e2-0250-41be-9b59-49e3e959d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3220cd6d-12a7-492b-b0dc-f262ec304fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1984993-10b9-4afe-aaac-2b66772fe152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09a05d0-bf05-435a-997e-9a241fb7a39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72070bd72aa14711a98e605ad0f31a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    \n",
    "    doc['question_text_vector'] = model.encode(question + ' ' + text)\n",
    "\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ee248e-06dd-4883-a120-658c4563fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval of results\n",
    "\n",
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e8c7ee8-50c2-4dc1-80a1-1f557b91d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60586173-99db-468a-985c-19e6b0ef6ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What if I miss a session?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'id': '5170565b'},\n",
       " {'question': 'Is it going to be live? When?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'id': '39fda9f0'},\n",
       " {'question': 'The same accuracy on epochs',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': '8. Neural Networks and Deep Learning',\n",
       "  'text': \"Problem description\\nThe accuracy and the loss are both still the same or nearly the same while training.\\nSolution description\\nIn the homework, you should set class_mode='binary' while reading the data.\\nAlso, problem occurs when you choose the wrong optimizer, batch size, or learning rate\\nAdded by Ekaterina Kutovaia\",\n",
       "  'id': '7d11d5ce'},\n",
       " {'question': 'Useful Resource for Missing Data Treatment\\nhttps://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python/notebook',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': '2. Machine Learning for Regression',\n",
       "  'text': '(Hrithik Kumar Advani)',\n",
       "  'id': '81b8e8d0'},\n",
       " {'question': 'Will I get a certificate if I missed the midterm project?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"Yes, it's possible. See the previous answer.\",\n",
       "  'id': '1d644223'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_text_vector_knn(dict(\n",
    "    question='Are sessions recorded if I miss one?',\n",
    "    course='machine-learning-zoomcamp'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ef0ab-23c3-403f-968a-122ec023f536",
   "metadata": {},
   "source": [
    "## The RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7675c0a-e492-452d-8aa2-3e1f6356d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "        You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "        Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "        \n",
    "        QUESTION: {question}\n",
    "        \n",
    "        CONTEXT: \n",
    "        {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "953731b4-cf9f-49f8-a2d9-75d98d23c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2879cfd6-bf4e-4a1b-a313-c1bcabc7cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188c38f-37c9-46a9-a0b2-bb48f67ae905",
   "metadata": {},
   "source": [
    "#### Use cheaper model => claude-3-haiku-20240307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "366e2f2d-8c1b-4835-9f06-a899a3489930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model=\"claude-3-5-sonnet-20240620\"):\n",
    "    response = client.messages.create(\n",
    "        # model=\"claude-3-haiku-20240307\",\n",
    "        model = model,\n",
    "        max_tokens = 1024,\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # print usage\n",
    "    print(response.usage)\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f8669a0-e4e4-4bdf-868a-88e5a84d5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously: rag(query: str) -> str\n",
    "def rag(query: dict, model=\"claude-3-5-sonnet-20240620\") -> str:\n",
    "    search_results = question_text_vector_knn(query)\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "159c942f-83f7-42c5-9526-d5e5b72517a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage(input_tokens=424, output_tokens=118)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextBlock(text='Based on the provided context, I can answer your question as follows:\\n\\nYes, sessions are recorded if you miss one. The course FAQ states that \"Everything is recorded, so you won\\'t miss anything.\" This applies to both the pre-recorded course videos and the occasional live office hours sessions. If you miss a session, you will be able to watch the recording later. Additionally, you can ask questions in advance for office hours, which will be covered during the live stream, and these sessions are also recorded. You can always ask questions in Slack as well.', type='text')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(ground_truth[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4466176-ef41-43ef-964c-758a12853442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx['5170565b']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20863bea-2506-40f1-a4e9-36e1484deefb",
   "metadata": {},
   "source": [
    "## Cosine Similarity Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "537076ac-3dd4-4f3f-9d82-d122f0562d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== haiku model ===\n",
    "# answer_orig = \"\"\"\n",
    "# Yes, the sessions are recorded, so you won't miss anything if you miss a live session. The course videos are pre-recorded,\n",
    "# and the occasional live office hours sessions are also recorded. You can access all the recordings in the course playlist on\n",
    "# YouTube.\n",
    "# \"\"\"\n",
    "\n",
    "answer_orig = \"\"\"\n",
    "Yes, sessions are recorded if you miss one. The course FAQ states that \"Everything is recorded, so you won't miss anything.\"\n",
    "This applies to both the pre-recorded course videos and the occasional live office hours sessions. If you miss a session, you\n",
    "will be able to watch the recording later. Additionally, you can ask questions in advance for office hours, which will be\n",
    "covered during the live stream, and these sessions are also recorded. You can always ask questions in Slack as well.\n",
    "\"\"\"\n",
    "\n",
    "answer_llm = \"\"\"\n",
    "Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and\n",
    "we will cover them during the live stream. Also, you can always ask questions in Slack.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2e23ea0-48bf-44a5-b427-eadf8c182c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_llm = model.encode(answer_llm)\n",
    "v_orig = model.encode(answer_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86cfe023-2eb8-4a2b-8b3a-6bbda9a8365c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71898925"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute cosine similarity between \"v_llm\" and \"v_orig\"\n",
    "v_llm.dot(v_orig) # diff due to openAI being used in vid\n",
    "\n",
    "# Has a high degree of similarity\n",
    "\n",
    "# haiku mode result is 0.5698763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e142c1b-e58d-46cc-82e9-42d9574dcb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '0227b872'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3ebc82a-0c49-495b-84a0-d81a53edbea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44a747a4-42ea-49c6-b6d7-03e5c31dd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145fb09-e1fd-42d9-bd7f-5f06d6282aa8",
   "metadata": {},
   "source": [
    "didn't run due to API costs --- used output from video\n",
    "\n",
    "```python\n",
    "for i, rec in enumerate(tqdm(ground_truth)):\n",
    "    if i in answers:\n",
    "        continue\n",
    "\n",
    "    answer_llm = rag(rec)\n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    answers[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }\n",
    "\n",
    "```\n",
    "\n",
    "interested in => `answers.values()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303cee4-559d-4ac5-8ad3-d9248a9f072d",
   "metadata": {},
   "source": [
    "Also didn't run code below --- **All code below uses openAI**\n",
    "\n",
    "```python\n",
    "# updates \"ground_truth\" and outputs results to csv file\n",
    "\n",
    "results_gpt4o = [None] * len(ground_truth)\n",
    "\n",
    "for i, val in answers.items():\n",
    "    results_gpt4o[i] = val.copy()\n",
    "    results_gpt4o[i].update(ground_truth[i])\n",
    "\n",
    "df_gpt4o = pd.DataFrame(results_gpt4o)\n",
    "\n",
    "!mkdir data\n",
    "\n",
    "df_gpt4o.to_csv('data/results-gpt4o.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643b338-f8f8-42cd-9227-7fe09cfee257",
   "metadata": {},
   "source": [
    "## Code below can be used for faster processing as it executes in parallel\n",
    "\n",
    "*Note:* Best to use if have better PC resources -- costs can vary depending on model...sometimes high\n",
    "\n",
    "```python\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pool = ThreadPoolExecutor(max_workers=6)\n",
    "\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def process_record(rec):\n",
    "    model = 'gpt-3.5-turbo'\n",
    "    answer_llm = rag(rec, model=model)\n",
    "    \n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    return {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }\n",
    "\n",
    "\n",
    "print(process_record(ground_truth[10]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6cb8bf-5575-4ba3-8a28-7d291f25cdb6",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "results_gpt35 = map_progress(pool, ground_truth, process_record)\n",
    "\n",
    "df_gpt35 = pd.DataFrame(results_gpt35)\n",
    "df_gpt35.to_csv('data/results-gpt35.csv', index=False)\n",
    "\n",
    "# check results\n",
    "!head data/results-gpt35.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91814280-c4f7-4c25-9159-9580e1ae2cb5",
   "metadata": {},
   "source": [
    "# Video 4.3 Ends Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f9652-a7be-4c84-af0f-d0e0b4aa4fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
